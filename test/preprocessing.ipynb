{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理\n",
    "## 文本预处理\n",
    "> Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证bert是否成功下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/DMSE/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'have', 'a', 'good', 'time', ',', 'thank', 'you', '.']\n",
      "load bert model over\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel,BertTokenizer\n",
    "import os\n",
    "\n",
    "\n",
    "BERT_PATH = '../modules/models/BERT'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_PATH)\n",
    "\n",
    "print(tokenizer.tokenize('I have a good time, thank you.'))\n",
    "\n",
    "bert = BertModel.from_pretrained(BERT_PATH)\n",
    "\n",
    "print('load bert model over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# 设置模型路径\n",
    "BERT_PATH = '../modules/models/BERT'\n",
    "\n",
    "# 加载本地 BERT 模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_PATH)\n",
    "model = BertModel.from_pretrained(BERT_PATH)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 3179\n",
      "IMGID: 1860693.jpg\n",
      "Sentence: RT @ ltsChuckBass : $T$ is everything # MCM Chuck Bass\n",
      "Labels: 1\n",
      "\n",
      "IMGID: 1860693.jpg\n",
      "Sentence: RT @ ltsChuckBass : Chuck Bass is everything $T$ # MCM\n",
      "Labels: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"读取数据集并返回句子列表、标签列表和图片ID列表\"\"\"\n",
    "    sentences, labels, img_ids = [], [], []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # 每条记录按 4 行解析\n",
    "    for i in range(0, len(lines), 4):\n",
    "        # 确保数据完整性（防止不足 4 行的情况）\n",
    "        if i + 3 >= len(lines):\n",
    "            print(f\"Skipping incomplete record at line {i}\")\n",
    "            break\n",
    "\n",
    "        sentence_1 = lines[i].strip()  # 第一行：文本句子\n",
    "        sentence_2 = lines[i + 1].strip()  # 第二行：额外文本\n",
    "        label = int(lines[i + 2].strip())  # 第三行：标签，转为整数\n",
    "        img_id = lines[i + 3].strip()  # 第四行：图片ID\n",
    "\n",
    "        # 合并句子\n",
    "        full_sentence = f\"{sentence_1} {sentence_2}\"\n",
    "        sentences.append(full_sentence)\n",
    "        labels.append(label)\n",
    "        img_ids.append(img_id)\n",
    "\n",
    "    return sentences, labels, img_ids\n",
    "\n",
    "# 读取数据并输出前两个句子及其对应的 IMGID\n",
    "train_path = \"../src_data/data_baseline/twitter2015/train.txt\"  # 替换为你的训练集路径\n",
    "sentences, labels, img_ids = load_data(train_path)\n",
    "\n",
    "print(f\"Number of records: {len(img_ids)}\")\n",
    "# 打印前两个句子及其标签和图像ID\n",
    "for i in range(2):\n",
    "    print(f\"IMGID: {img_ids[i]}\")\n",
    "    print(\"Sentence:\", sentences[i])\n",
    "    print(\"Labels:\", labels[i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 1024])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# 加载BERT模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_PATH)\n",
    "model = BertModel.from_pretrained(BERT_PATH)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 生成词向量的函数\n",
    "def get_bert_embeddings(sentences):\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for sentence in sentences:\n",
    "            # 分词\n",
    "            inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "            input_ids = inputs['input_ids'].to(device)\n",
    "            attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "            # 获取BERT输出\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            embeddings = outputs.last_hidden_state  # [batch_size, seq_len, hidden_dim]\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "\n",
    "    return all_embeddings\n",
    "\n",
    "# 获取词向量\n",
    "sentence_embeddings = get_bert_embeddings(sentences)\n",
    "\n",
    "# 打印第一个句子的词向量形状\n",
    "print(sentence_embeddings[0].shape)  # (batch_size, max_seq_len, word_embedding_dimension)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片预处理\n",
    "> ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vit_pytorch import ViT\n",
    "\n",
    "v = ViT(\n",
    "    image_size = 256,\n",
    "    patch_size = 32,\n",
    "    num_classes = 1000,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "\n",
    "img = torch.randn(1, 3, 256, 256)\n",
    "\n",
    "preds = v(img) # (1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 49805.jpg, Output shape: torch.Size([1000])\n",
      "Image: 8700.jpg, Output shape: torch.Size([1000])\n",
      "Image: 478494.jpg, Output shape: torch.Size([1000])\n",
      "Image: 1092215.jpg, Output shape: torch.Size([1000])\n",
      "Image: 654966.jpg, Output shape: torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# 定义预处理步骤\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # 调整图片大小到模型输入尺寸\n",
    "    transforms.ToTensor(),         # 转为张量\n",
    "    transforms.Normalize(           # 使用 ImageNet 的均值和标准差归一化\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# 加载本地图片\n",
    "def load_image(image_path):\n",
    "    \"\"\"加载图片并进行预处理\"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")  # 确保图片是 RGB 模式\n",
    "    img_tensor = preprocess(img)  # 应用预处理\n",
    "    return img_tensor.unsqueeze(0)  # 增加 batch 维度\n",
    "\n",
    "# 批量处理图片\n",
    "def process_images_in_folder(folder_path, model):\n",
    "    \"\"\"批量处理文件夹中的图片\"\"\"\n",
    "    results = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):  # 只处理图片文件\n",
    "            try:\n",
    "                img_tensor = load_image(image_path)\n",
    "                with torch.no_grad():  # 预测时不需要计算梯度\n",
    "                    preds = model(img_tensor)  # 模型预测\n",
    "                results[file_name] = preds.squeeze(0)  # 去除 batch 维度\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_name}: {e}\")\n",
    "    return results\n",
    "\n",
    "# 测试代码\n",
    "image_folder = \"../img_data/twitter2015\"  # 替换为你的图片文件夹路径\n",
    "v.eval()  # 将模型设置为评估模式（关闭 dropout 和 batchnorm）\n",
    "results = process_images_in_folder(image_folder, v)\n",
    "\n",
    "# 打印前几张图片的预测结果\n",
    "for file_name, output in list(results.items())[:5]:  # 只显示前 5 个\n",
    "    print(f\"Image: {file_name}, Output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8593e-02,  3.0752e-01, -3.1113e-01,  5.1795e-01, -9.4753e-02,\n",
       "         -5.7106e-01,  5.4270e-01, -7.7945e-02,  1.2067e+00, -5.3213e-01,\n",
       "         -1.4911e-01,  9.8372e-01, -2.1954e-01, -2.1041e-02,  3.6621e-01,\n",
       "          1.7244e-01,  1.0807e+00,  7.2316e-01, -1.4327e+00,  5.1862e-01,\n",
       "         -1.0203e+00,  1.5916e-01,  8.0286e-02,  1.8359e-01, -1.1854e-01,\n",
       "          1.3533e+00,  5.6979e-02,  4.4181e-01, -3.9340e-01,  2.9487e-01,\n",
       "         -5.6481e-01, -2.9753e-01,  1.2856e+00,  7.5437e-01, -4.4568e-01,\n",
       "         -1.0121e+00, -1.4310e+00,  6.2169e-01, -2.7196e-01,  1.5859e-01,\n",
       "         -5.4618e-02, -9.3260e-01, -6.0375e-01, -8.4579e-01, -6.9165e-01,\n",
       "         -6.4110e-01,  9.8860e-01, -8.2532e-02,  4.3525e-01, -1.3493e-01,\n",
       "          7.2447e-01,  8.1049e-01, -2.3911e-01, -4.4767e-01, -6.8853e-01,\n",
       "          9.5735e-01,  4.2351e-01, -5.9532e-01, -3.8985e-01,  1.6900e-02,\n",
       "         -1.7104e-01, -1.0015e+00,  1.3534e-01, -5.1001e-01,  2.5451e-01,\n",
       "          5.7262e-01, -9.1649e-01, -1.1339e+00,  5.9308e-01, -3.3673e-01,\n",
       "         -2.7628e-01,  4.0861e-01,  6.9871e-01, -3.7213e-01, -2.4122e-01,\n",
       "          6.6302e-01, -4.6085e-01,  8.4925e-01, -1.8746e-01,  9.7971e-01,\n",
       "         -1.8437e-02, -6.6302e-01, -1.4201e-01, -9.2129e-01, -6.1450e-01,\n",
       "          4.0964e-01, -4.2115e-02,  7.0428e-01,  3.5418e-01, -3.3873e-01,\n",
       "          3.5671e-01,  6.4816e-01, -6.3443e-01, -4.3363e-01, -1.1341e-01,\n",
       "          4.3425e-01, -9.4955e-02, -1.9675e-01, -3.0221e-01, -1.8025e-01,\n",
       "          4.8273e-01, -1.2755e+00, -3.2719e-01,  1.0082e+00,  1.6515e-01,\n",
       "         -1.5888e-01,  4.0936e-01, -7.5897e-01, -6.0593e-02,  2.6038e-01,\n",
       "          2.8137e-02, -2.2407e-01,  2.2288e-01,  4.7933e-01, -9.3457e-02,\n",
       "         -9.2710e-02, -5.7941e-01, -9.6621e-01, -1.0701e+00, -9.7055e-02,\n",
       "          3.7425e-01,  8.8909e-01, -3.8018e-01, -7.0336e-02, -7.5856e-02,\n",
       "         -4.7338e-02, -7.4036e-01,  5.0078e-01, -5.4734e-01,  1.5329e-01,\n",
       "          2.2587e-01, -1.6064e-01, -2.6103e-01,  3.8838e-01, -2.0529e-01,\n",
       "         -4.4155e-01,  1.6547e-01,  7.3445e-01, -2.2089e-01,  2.3127e-01,\n",
       "         -7.7670e-01,  4.2149e-01,  2.9675e-01, -7.9952e-01,  1.0252e+00,\n",
       "         -1.2893e-01,  2.4980e-01,  5.7062e-01, -9.8250e-01, -5.8792e-01,\n",
       "         -1.1965e+00, -6.6170e-01,  4.9365e-01, -7.2846e-03,  9.0813e-01,\n",
       "          1.8634e-01,  4.9261e-01, -1.2663e+00,  7.3114e-01, -2.8321e-04,\n",
       "          5.3065e-01,  1.0266e+00, -5.7620e-01,  9.2976e-01,  2.9615e-02,\n",
       "          1.6317e-01,  5.5582e-01,  1.3640e-01, -5.8987e-01,  4.5004e-01,\n",
       "         -1.3272e-01,  8.4825e-02,  4.2060e-01,  3.2315e-01,  1.0438e+00,\n",
       "          8.1753e-01, -5.8200e-01, -1.7000e-01, -1.5200e-01,  1.0548e-02,\n",
       "          2.9909e-02,  6.1800e-01,  6.8080e-01, -5.0576e-01, -5.4542e-01,\n",
       "         -1.4731e+00, -1.2460e-01,  2.0106e-01,  4.6261e-02,  4.8530e-01,\n",
       "         -8.6160e-01,  3.5426e-02, -1.0042e+00,  1.8187e-01, -6.2583e-01,\n",
       "          8.4273e-01,  8.6096e-01, -4.2796e-01,  2.4295e-01, -5.4630e-01,\n",
       "         -7.0475e-01, -3.1863e-01,  5.9218e-01,  1.5004e-01, -3.5564e-01,\n",
       "         -3.7627e-01,  3.4181e-01, -6.0455e-01, -3.1930e-01, -9.7076e-01,\n",
       "         -2.6940e-01,  4.9782e-01,  3.6299e-01, -7.7759e-01, -1.0098e+00,\n",
       "         -1.4136e+00,  2.6182e-01, -5.1889e-01,  7.2003e-02, -1.0509e+00,\n",
       "          5.0581e-01,  4.6605e-01,  1.7582e-01, -8.6531e-01,  1.1189e+00,\n",
       "         -6.2881e-01, -5.0904e-01,  2.4397e-01, -4.6256e-01,  8.6200e-01,\n",
       "         -2.6850e-02, -7.2941e-01,  4.5847e-01,  6.6348e-01, -4.8236e-01,\n",
       "          4.0060e-01,  5.9728e-01,  3.0049e-01, -8.9576e-02,  9.0536e-01,\n",
       "          9.9619e-02, -5.9780e-01,  6.4688e-01,  1.3672e+00,  3.4335e-01,\n",
       "          1.1079e-01, -8.5069e-01, -4.2659e-02, -4.5116e-01, -6.1574e-01,\n",
       "          6.0823e-01, -9.1204e-01,  5.3664e-02, -1.3668e-02,  5.7034e-01,\n",
       "          1.5907e+00,  4.9048e-01,  3.4798e-02, -1.3137e+00, -1.4374e+00,\n",
       "         -4.4557e-01, -6.7164e-01, -3.2490e-02, -1.7554e-01, -9.4492e-03,\n",
       "          6.6375e-01,  4.5053e-01, -6.7716e-02, -5.5689e-01, -7.8265e-01,\n",
       "         -4.2766e-01, -2.5632e-02, -7.3054e-01, -2.2085e-01,  3.9127e-01,\n",
       "          7.2168e-01, -1.0545e+00,  9.4964e-01, -7.8320e-03, -1.0923e+00,\n",
       "          6.9289e-01, -1.5527e-01,  3.3268e-01, -3.5403e-01,  2.5906e-01,\n",
       "          8.8056e-02,  5.3941e-01,  1.2925e-01, -4.2353e-01, -1.5441e+00,\n",
       "         -7.2515e-01, -2.7616e-01,  5.6915e-01,  1.1186e+00, -7.1205e-02,\n",
       "         -7.2208e-01,  1.0280e+00,  2.9252e-01, -8.0907e-01,  3.6360e-01,\n",
       "         -1.0956e-01, -2.5587e-01, -1.8549e-01,  1.2186e-01,  7.4904e-01,\n",
       "         -2.3268e-01, -5.5409e-01, -9.3095e-01, -2.5066e-01,  9.7417e-01,\n",
       "          5.8561e-01,  3.5360e-02,  4.8440e-01, -8.6048e-01,  4.8340e-01,\n",
       "          8.3814e-01,  1.1637e+00,  3.9973e-01,  2.0071e-01, -3.0705e-01,\n",
       "          1.3865e-01,  6.8420e-02, -9.6855e-02,  7.4679e-01, -3.5175e-02,\n",
       "          8.1354e-01,  1.9615e-01,  9.5984e-02,  2.1444e-01,  1.3209e-01,\n",
       "         -1.8659e-01,  9.8245e-01, -2.3245e-01, -1.1214e-02, -3.4264e-01,\n",
       "          7.7588e-01,  4.1634e-01, -5.5093e-01, -3.1118e-01, -5.9371e-01,\n",
       "         -8.0606e-01,  1.3145e+00,  7.8152e-01,  7.6877e-02,  9.4419e-01,\n",
       "          8.9230e-01,  1.0093e+00,  1.0951e-01,  8.8496e-02,  1.9614e-01,\n",
       "          5.7783e-01, -5.8053e-01,  3.0456e-01, -1.9336e-01, -2.6924e-01,\n",
       "         -4.6357e-01,  5.6884e-01,  4.1704e-01,  2.2473e-02,  7.8992e-02,\n",
       "         -2.5638e-01, -1.0444e+00, -6.4075e-01, -2.6757e-01, -2.4608e-01,\n",
       "         -1.7913e-01, -4.6266e-03, -2.5991e-01, -3.0360e-01,  1.6347e-01,\n",
       "         -1.4409e+00,  9.5226e-03, -4.7113e-02, -5.9305e-01,  9.0973e-01,\n",
       "          6.8742e-01, -5.5903e-01,  2.2653e-01, -1.8088e-01, -4.9395e-01,\n",
       "         -3.1220e-02, -7.5347e-01, -1.6347e-01, -6.8553e-01,  4.4313e-01,\n",
       "          9.4035e-01, -1.0617e-03, -5.6495e-01, -4.0370e-01, -5.3480e-01,\n",
       "          3.8786e-01, -6.9535e-01,  6.4608e-01, -9.5092e-01, -5.1875e-02,\n",
       "         -2.0736e-01, -1.3212e-02, -9.3183e-01,  3.5522e-01,  1.3224e+00,\n",
       "          1.0887e+00,  1.8955e-01,  3.4724e-02, -4.6762e-01,  3.4604e-01,\n",
       "          1.2669e-01,  3.4023e-01, -7.7640e-01, -1.9412e-01, -6.6504e-01,\n",
       "          6.0659e-01, -1.1515e-01,  7.9962e-01, -4.5286e-01, -8.3667e-01,\n",
       "         -1.6001e-01, -1.1446e+00,  9.0151e-01, -5.6571e-02,  3.6335e-01,\n",
       "         -7.1982e-03, -8.8179e-02, -2.0258e-01, -4.2911e-01,  1.3544e-01,\n",
       "         -2.0019e-01,  8.8602e-02,  9.2871e-01, -5.4194e-01,  5.9211e-01,\n",
       "          5.8702e-01,  9.0608e-02, -1.8691e-01,  3.4675e-01,  2.8540e-01,\n",
       "         -6.3865e-01, -1.0428e-01, -2.0584e-01, -3.5725e-01, -1.2166e+00,\n",
       "          1.4336e-01,  3.2761e-01, -3.5312e-01, -4.5495e-01, -6.6278e-01,\n",
       "          4.5901e-01, -3.5718e-01,  2.4641e-01,  3.0232e-01,  8.4676e-01,\n",
       "          2.6851e-02, -6.9906e-01,  2.0416e-01, -1.7573e-01,  1.2061e+00,\n",
       "         -9.6305e-01,  1.6423e-01,  1.6894e-01, -1.2008e-01,  1.2570e+00,\n",
       "         -4.4488e-01, -3.3366e-01, -2.8670e-01, -1.0006e+00, -8.3276e-03,\n",
       "          1.2443e-02,  2.1007e-01,  1.8669e-01, -1.0541e+00,  1.4276e-01,\n",
       "         -6.3866e-01, -6.4270e-01,  1.1532e+00, -1.8493e+00,  3.0553e-03,\n",
       "          5.5403e-01,  1.3434e-01,  8.4696e-01,  2.1730e-01,  2.3762e-02,\n",
       "         -2.1982e-01, -6.5325e-01,  7.2119e-01, -1.7196e-01, -2.5707e-01,\n",
       "          6.6259e-02,  7.8557e-01, -1.7428e-03, -1.7839e-01,  5.3326e-01,\n",
       "         -6.8599e-01,  3.1179e-02,  4.1884e-02,  2.4256e-01, -5.8397e-01,\n",
       "          3.5421e-01, -6.6472e-01, -5.8217e-01, -1.9954e-01,  1.0836e-01,\n",
       "         -1.4243e-01, -5.9624e-01, -1.1901e-02,  1.0443e-01,  1.9379e-01,\n",
       "          1.1879e-01, -6.2611e-01,  1.5054e-01,  2.0180e-01,  7.3237e-02,\n",
       "         -1.4158e+00, -1.6431e-01,  9.2727e-01,  3.0518e-01, -2.0740e-01,\n",
       "         -1.2731e+00,  5.7594e-01, -8.4547e-01, -9.7372e-01,  6.0676e-01,\n",
       "          6.0472e-01,  7.1571e-01,  5.0189e-01,  1.1696e+00, -3.0196e-01,\n",
       "         -5.5420e-01, -5.8541e-01,  2.8415e-01, -4.3808e-01,  2.9339e-01,\n",
       "         -3.9557e-01,  2.0100e-01, -1.1108e+00, -1.7722e-01,  3.2389e-01,\n",
       "         -4.7160e-01, -2.3097e-01,  4.6823e-01,  4.0709e-01,  7.3306e-01,\n",
       "          2.7118e-01,  6.9715e-01, -1.6067e-01,  6.2491e-01, -9.3941e-01,\n",
       "         -2.7367e-01, -5.0556e-01,  5.0200e-01,  1.6090e-01, -1.2876e-01,\n",
       "          6.7949e-01,  1.1015e+00, -4.2096e-01, -6.0490e-01, -2.7839e-01,\n",
       "          9.6460e-01, -5.3236e-01,  2.7915e-01,  2.5281e-01, -3.5008e-02,\n",
       "         -3.3314e-01, -4.5091e-01,  1.3450e-01, -5.4674e-01, -1.7727e-01,\n",
       "         -2.1097e-01,  1.6440e+00,  4.5554e-01,  5.1346e-01,  4.9977e-01,\n",
       "          6.1763e-01,  6.6394e-01,  1.7830e-01, -2.8774e-01,  1.3571e+00,\n",
       "         -9.4787e-01,  1.8995e-02, -1.0613e-01, -5.8721e-02,  5.9736e-01,\n",
       "          1.5739e+00, -2.7293e-02, -8.8217e-01,  3.0503e-01,  2.5623e-01,\n",
       "         -5.1173e-01, -4.9647e-01, -3.6076e-01,  8.2464e-01, -2.1543e-01,\n",
       "          6.7485e-02, -6.1587e-02, -6.3968e-01,  4.3398e-01, -1.9658e-01,\n",
       "          2.9971e-02,  2.1305e-01,  4.9342e-01, -1.9134e-01, -1.0469e-01,\n",
       "          2.0997e-01,  9.5352e-01, -4.5184e-02, -8.1842e-02,  1.0311e+00,\n",
       "         -2.5886e-01,  9.0351e-01, -3.6013e-01, -1.1007e+00,  2.3360e-01,\n",
       "         -4.2123e-01, -8.8401e-01, -1.1053e-01, -3.6757e-01, -1.5948e-01,\n",
       "          3.9141e-01, -3.0983e-01, -9.6210e-01,  3.3124e-01, -4.8044e-01,\n",
       "         -2.3500e-01, -1.6227e-01,  3.1213e-02, -1.2892e+00, -8.4199e-01,\n",
       "          7.3994e-01, -7.6085e-01, -1.1992e-01,  1.0347e+00,  3.0609e-01,\n",
       "          5.6632e-02,  4.8216e-01,  5.1753e-01, -1.2561e+00, -6.4566e-01,\n",
       "         -1.4488e-01, -5.7295e-02, -3.7717e-01,  4.4585e-02, -2.1379e-01,\n",
       "         -3.7801e-01, -9.7240e-03,  1.0575e+00,  3.4371e-01,  7.3830e-01,\n",
       "          4.0051e-01,  6.0042e-01,  1.9492e-01,  1.9987e-01, -8.2065e-01,\n",
       "          1.0746e-01,  1.1814e+00,  8.1617e-01,  2.8941e-01, -1.4172e-01,\n",
       "         -1.5550e-01,  6.9619e-01, -1.4155e+00, -3.3439e-01, -4.9198e-01,\n",
       "          2.7824e-01, -4.4761e-02, -2.5644e-01,  4.9920e-01, -5.5980e-01,\n",
       "          5.4334e-01, -5.4460e-01, -6.6108e-02,  1.4634e+00,  6.2721e-01,\n",
       "         -8.0640e-02,  5.6338e-01, -4.6004e-01,  7.2720e-01,  2.2752e-01,\n",
       "          3.1156e-02, -2.1770e-01, -2.5179e-01, -1.1241e-01, -3.4171e-01,\n",
       "         -4.2465e-01,  5.8816e-01, -8.3163e-01,  4.2128e-01, -7.1121e-02,\n",
       "         -4.4628e-01,  9.7655e-01,  8.8742e-01,  2.2965e-01, -7.1009e-01,\n",
       "         -9.3799e-01,  6.8035e-01,  5.7012e-01,  6.6082e-01,  2.0505e-01,\n",
       "         -1.0276e+00, -1.2638e+00,  2.9248e-02, -2.1074e-01, -5.6398e-01,\n",
       "          9.7610e-02, -2.1626e-01, -5.5389e-01, -1.1981e-01, -6.6828e-01,\n",
       "         -2.0790e-01, -1.2275e-01, -1.4586e-02,  6.6166e-01, -1.5536e-01,\n",
       "         -5.1527e-01, -1.1204e-02,  5.0155e-01, -1.7894e-02, -1.1581e-01,\n",
       "          8.7555e-01,  6.2694e-01, -6.5539e-01,  5.7706e-01, -5.4517e-01,\n",
       "         -1.2120e-01,  3.5373e-01,  2.8427e-01, -2.1545e-01,  3.2678e-01,\n",
       "         -1.1350e-01, -3.6929e-01, -2.0404e-01, -4.8823e-01, -2.3769e-01,\n",
       "          7.2313e-01,  5.9801e-01, -9.1211e-02, -5.9550e-01,  5.3163e-01,\n",
       "          4.9109e-01,  4.8103e-01,  7.4161e-01,  4.2534e-01, -1.4797e+00,\n",
       "         -2.6740e-01,  1.9972e-01, -3.7335e-01, -6.5577e-01, -2.6630e-01,\n",
       "         -4.0768e-01, -4.7976e-01, -1.4009e-01, -2.6996e-01,  3.0686e-01,\n",
       "          3.8348e-01, -4.1155e-01,  3.0014e-01, -3.9156e-01, -2.2786e-01,\n",
       "          2.0357e-01, -3.8189e-02,  3.2245e-01, -5.1835e-01,  6.5546e-01,\n",
       "         -7.0396e-01, -2.3704e-01, -9.6212e-01,  5.5137e-01, -5.5388e-01,\n",
       "          3.8240e-01,  1.0089e+00,  4.3261e-01, -9.3514e-02, -2.5643e-02,\n",
       "         -1.1691e+00, -3.8757e-01,  1.6261e-01, -7.9202e-01,  1.3805e+00,\n",
       "          3.9255e-01,  4.8941e-01,  4.0737e-01, -2.7673e-01, -2.2363e-02,\n",
       "          3.2554e-02,  3.3830e-01, -3.7971e-01,  6.1176e-02, -1.3796e-01,\n",
       "          8.8365e-01, -2.1961e-02, -2.0480e-01,  9.4177e-01,  1.5047e+00,\n",
       "         -1.4161e-01, -1.1626e-02,  5.9362e-01,  9.1667e-02,  1.1018e-01,\n",
       "         -2.2074e-01, -7.3308e-01,  7.1886e-01,  1.1634e+00, -5.4517e-02,\n",
       "         -1.5955e-01, -2.7756e-01,  3.5411e-01,  6.5018e-01, -2.3744e-01,\n",
       "          3.0583e-02, -1.4580e-01,  5.8122e-01,  1.2529e-01, -1.4624e-01,\n",
       "         -1.5117e+00, -5.6032e-01, -1.5504e-01, -3.8101e-01, -1.3388e+00,\n",
       "         -7.9350e-01,  6.0150e-01,  7.3283e-02, -7.3360e-02,  3.9195e-02,\n",
       "          4.7186e-01,  1.8247e-01, -3.8518e-01, -6.6995e-01,  7.0183e-02,\n",
       "         -8.0602e-02, -3.9811e-01, -3.8339e-01,  6.4661e-01, -2.1888e-01,\n",
       "          1.0137e+00, -1.2293e-02, -4.8121e-01, -9.0711e-01,  1.8328e-01,\n",
       "          1.2343e+00, -4.3401e-03,  6.4930e-01,  8.4561e-01,  5.5647e-01,\n",
       "         -1.2255e-01,  1.9725e-01,  2.9579e-01,  1.0479e+00, -3.2554e-01,\n",
       "         -1.0508e+00, -6.6607e-01,  4.4339e-01, -3.9931e-01, -2.5289e-01,\n",
       "          3.5889e-02, -9.2348e-01, -9.2762e-01, -2.2603e-01,  6.0294e-01,\n",
       "          3.4208e-01, -2.4467e-01, -2.9241e-01,  1.0227e+00, -3.9372e-01,\n",
       "          6.5198e-01, -2.1903e-01, -4.6547e-01,  9.8089e-01,  3.8544e-01,\n",
       "         -4.4317e-01,  1.3300e-01, -1.8382e-01,  2.8597e-01, -1.4546e+00,\n",
       "         -3.3535e-01, -1.2510e-01,  3.2734e-01, -1.0296e+00,  8.2981e-01,\n",
       "         -2.9526e-01,  8.9502e-01, -1.2563e+00, -9.7053e-01,  6.1507e-01,\n",
       "          2.1590e-01, -1.4858e-01, -6.0919e-02,  1.0367e+00, -9.5643e-02,\n",
       "         -3.4599e-01, -2.9975e-02,  5.1391e-01, -1.2781e-03,  4.2069e-01,\n",
       "          5.3459e-01,  2.6055e-03, -4.0162e-01, -5.2095e-01,  4.5423e-01,\n",
       "         -3.6122e-01,  5.7596e-02, -4.6114e-02,  1.3122e-01,  1.0301e-01,\n",
       "          1.0124e+00,  6.7223e-01,  2.8310e-01,  2.5520e-01, -6.7917e-01,\n",
       "          7.0976e-01, -6.8137e-01, -8.0521e-01, -5.1851e-01, -2.7214e-01,\n",
       "         -3.8634e-02, -3.8254e-01, -6.0937e-01, -4.7963e-01, -5.0416e-01,\n",
       "          5.4049e-01,  7.1253e-02,  4.9236e-01, -2.9197e-01, -7.3346e-01,\n",
       "          3.6413e-01,  8.6503e-01, -4.6389e-01,  7.3929e-01, -2.3751e-01,\n",
       "         -5.4176e-01, -2.2754e-01, -4.8975e-01, -8.0745e-01,  5.4370e-01,\n",
       "         -5.3378e-01,  4.3920e-01, -7.5071e-01, -7.7349e-01,  4.0533e-01,\n",
       "          2.1783e-01,  3.2362e-01,  3.4417e-01,  1.7001e-01,  5.8981e-03,\n",
       "          5.7217e-01, -6.2754e-01, -4.4311e-01, -7.1918e-02,  3.7702e-02,\n",
       "         -1.2959e+00,  9.9588e-02, -4.3945e-01, -4.6411e-01, -4.0803e-02,\n",
       "          1.6810e-01, -4.5827e-01,  4.7633e-01, -1.1333e+00,  6.7769e-01,\n",
       "         -1.2710e+00, -1.8281e-01,  1.3073e+00, -3.3345e-01, -1.0457e+00,\n",
       "         -3.9059e-02, -2.1212e-01, -1.1307e+00,  1.0378e+00,  3.1889e-01,\n",
       "         -1.3501e-01, -5.1061e-01, -7.6519e-01, -1.9957e-01,  4.6068e-01,\n",
       "          3.6213e-01, -4.1794e-01, -8.3929e-01,  7.1430e-01, -7.6118e-01,\n",
       "         -6.7490e-02,  2.9763e-01, -9.7658e-01, -7.7601e-03,  6.2344e-01,\n",
       "         -1.4333e-01, -2.3974e-01,  3.5504e-01, -1.2703e-01,  1.4471e-01,\n",
       "         -3.8303e-01, -1.7138e-01, -5.9611e-01, -3.7844e-01, -8.7753e-02,\n",
       "          9.7356e-02,  1.0675e+00, -2.3311e-01,  9.4445e-01,  3.4068e-01,\n",
       "         -5.3467e-01, -2.3555e-01,  4.1100e-01, -9.1066e-02,  4.6956e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMSE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
