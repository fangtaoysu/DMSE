{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理\n",
    "## 文本预处理\n",
    "> Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证bert是否成功下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# 设置模型路径\n",
    "BERT_PATH = '../modules/models/BERT'\n",
    "\n",
    "# 加载本地 BERT 模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_PATH)\n",
    "model = BertModel.from_pretrained(BERT_PATH)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 3179\n",
      "IMGID: 1860693.jpg\n",
      "Sentence: RT @ ltsChuckBass : $T$ is everything # MCM Chuck Bass\n",
      "Labels: 1\n",
      "\n",
      "IMGID: 1860693.jpg\n",
      "Sentence: RT @ ltsChuckBass : Chuck Bass is everything $T$ # MCM\n",
      "Labels: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"读取数据集并返回句子列表、标签列表和图片ID列表\"\"\"\n",
    "    sentences, labels, img_ids = [], [], []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # 每条记录按 4 行解析\n",
    "    for i in range(0, len(lines), 4):\n",
    "        # 确保数据完整性（防止不足 4 行的情况）\n",
    "        if i + 3 >= len(lines):\n",
    "            print(f\"Skipping incomplete record at line {i}\")\n",
    "            break\n",
    "\n",
    "        sentence_1 = lines[i].strip()  # 第一行：文本句子\n",
    "        sentence_2 = lines[i + 1].strip()  # 第二行：额外文本\n",
    "        label = int(lines[i + 2].strip())  # 第三行：标签，转为整数\n",
    "        img_id = lines[i + 3].strip()  # 第四行：图片ID\n",
    "\n",
    "        # 合并句子\n",
    "        full_sentence = f\"{sentence_1} {sentence_2}\"\n",
    "        sentences.append(full_sentence)\n",
    "        labels.append(label)\n",
    "        img_ids.append(img_id)\n",
    "\n",
    "    return sentences, labels, img_ids\n",
    "\n",
    "# 读取数据并输出前两个句子及其对应的 IMGID\n",
    "train_path = \"../src_data/data_baseline/twitter2015/train.txt\"  # 替换为你的训练集路径\n",
    "sentences, labels, img_ids = load_data(train_path)\n",
    "\n",
    "print(f\"Number of records: {len(img_ids)}\")\n",
    "# 打印前两个句子及其标签和图像ID\n",
    "for i in range(2):\n",
    "    print(f\"IMGID: {img_ids[i]}\")\n",
    "    print(\"Sentence:\", sentences[i])\n",
    "    print(\"Labels:\", labels[i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 1024])\n"
     ]
    }
   ],
   "source": [
    "# 生成词向量的函数\n",
    "def get_bert_embeddings(sentences):\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for sentence in sentences:\n",
    "            # 分词\n",
    "            inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "            input_ids = inputs['input_ids'].to(device)\n",
    "            attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "            # 获取BERT输出\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            embeddings = outputs.last_hidden_state  # [batch_size, seq_len, hidden_dim]\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "\n",
    "    return all_embeddings\n",
    "\n",
    "# 获取词向量\n",
    "sentence_embeddings = get_bert_embeddings(sentences)\n",
    "# 打印第一个句子的词向量形状\n",
    "print(sentence_embeddings[0].shape)  # (batch_size, max_seq_len, word_embedding_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片预处理\n",
    "> ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 197, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor, ViTModel\n",
    "from PIL import Image\n",
    "\n",
    "# 设置模型路径\n",
    "Vit_PATH = '../modules/models/Vit'\n",
    "\n",
    "image_path = '../img_data/twitter2015/0.jpg'\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "processor = ViTImageProcessor.from_pretrained(Vit_PATH)\n",
    "model = ViTModel.from_pretrained(Vit_PATH)\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "last_hidden_states.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([8288, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 设置模型路径和图片文件夹路径\n",
    "Vit_PATH = '../modules/models/Vit'\n",
    "image_folder = '../img_data/twitter2015'\n",
    "\n",
    "# 批量加载和预处理图片\n",
    "def preprocess_images(folder_path, processor):\n",
    "    pixel_values = []  # 用于存储所有图片的张量\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, file_name)\n",
    "        # 检查文件类型，确保是图片\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            try:\n",
    "                # 加载图片\n",
    "                image = Image.open(image_path).convert(\"RGB\")\n",
    "                # 使用处理器预处理\n",
    "                inputs = processor(images=image, return_tensors=\"pt\")\n",
    "                pixel_values.append(inputs[\"pixel_values\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_name}: {e}\")\n",
    "    # 将所有图片的张量堆叠成一个批量张量\n",
    "    if pixel_values:\n",
    "        batch_pixel_values = torch.cat(pixel_values, dim=0)  # 形状: (batch_size, 3, height, width)\n",
    "        return batch_pixel_values\n",
    "    else:\n",
    "        raise ValueError(\"No valid images found in the folder!\")\n",
    "\n",
    "# 调用批量预处理函数\n",
    "batch_inputs = preprocess_images(image_folder, processor)\n",
    "print(\"Batch input shape:\", batch_inputs.shape)  # 打印批量张量形状\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMSE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
